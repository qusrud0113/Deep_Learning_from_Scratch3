{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 2023.05.10\n",
        "파이토치 튜토리얼(https://tutorials.pytorch.kr/beginner/basics/quickstart_tutorial.html) 내용 공부 및 정리\n",
        "\n",
        "Google Colab으로 진행\n"
      ],
      "metadata": {
        "id": "MezPlKXo5Oil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Tensor\n",
        "Tensor는 PyTorch에서 모델의 입력(input), 출력(output), 부호화(encode)할 때 사용되는 자료구조입니다."
      ],
      "metadata": {
        "id": "gA1FJHmP-FtY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "pzLHEuWlxwlF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Datasets: save sample and label\n",
        "* DataLoader:wrap an iterable around the Datasets"
      ],
      "metadata": {
        "id": "RlE3Ufzn8W4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# directly create tensor\n",
        "data = [[1,2],[3,4]]\n",
        "x_data = torch.tensor(data)\n",
        "x_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87BtYEImEewL",
        "outputId": "cc28df67-5bb0-40ae-c6a7-73f84def67d7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor는 numpy의 array와 구조가 매우 유사합니다. 따라서 array를 tensor로 바꿀 수 도있고, tensor를 array로 바꿀 수도 있습니다."
      ],
      "metadata": {
        "id": "6ajAYycxE9vC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from numpy array to tensor\n",
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)\n",
        "x_np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4Pg2SS2Esih",
        "outputId": "eec79f89-555a-4427-f162-24aaa48efd13"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensor to numpy array\n",
        "np_array2 = x_np.numpy()\n",
        "np_array2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36W8jWEoFKV0",
        "outputId": "0ff90f18-59e9-4a9b-f319-de4f584612db"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor는 명시적으로 재정의(override)하지 않는다면, tensor의 속성(모양(shape), 자료 유형(dtype))을 유지합니다. \n",
        "\n",
        "다음의 예시는 아까 direct하게 만든 텐서를 이용하여 다른 텐서를 생성합니다."
      ],
      "metadata": {
        "id": "C5qpUW2BGDy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor Regenerate\n",
        "# ones_like(DATA) <- DATA의 구조를 그대로 따르면서 원소를 1로 채움 \n",
        "x_ones = torch.ones_like(x_data)\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "# rand_like(DATA) <- DATA의 구조를 그대로 따르면서 원소를 random[0,1)값으로 채움\n",
        "# 여기서 dtype을 float로 재정의함에 따라 x_data의 속성에 덮어씀.\n",
        "x_rand = torch.rand_like(x_data, dtype = torch.float)\n",
        "print(f\"Rand Tensor: \\n {x_rand} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-ymMN8DF8Qu",
        "outputId": "e2c6f5fe-6eb6-4cfd-a0ba-a3fa11be7d59"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Rand Tensor: \n",
            " tensor([[0.1728, 0.1027],\n",
            "        [0.0522, 0.8867]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 무작위 혹은 상수의 값으로 Tensor 만들기\n",
        "# shape는 Tensor의 Dimension을 나타내는 tuple입니다.\n",
        "# shape는 각각 차원의 수, row수, column수를 의미합니다.\n",
        "shape = (3,3,2)\n",
        "\n",
        "# rand는 random [0,1)의 값을, ones는 1, zeros는 0을 shape에 구조에 따라 생성합니다.\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"rand_tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"ones_tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"zeros_tensor: \\n {zeros_tensor} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f8sIs4tIDRT",
        "outputId": "db1c7204-812f-4ab3-b855-9faf46391dd3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rand_tensor: \n",
            " tensor([[[0.1139, 0.5826],\n",
            "         [0.8124, 0.3109],\n",
            "         [0.3868, 0.5575]],\n",
            "\n",
            "        [[0.6286, 0.4110],\n",
            "         [0.8062, 0.7873],\n",
            "         [0.7001, 0.6496]],\n",
            "\n",
            "        [[0.5611, 0.7982],\n",
            "         [0.3693, 0.2896],\n",
            "         [0.7939, 0.0520]]]) \n",
            "\n",
            "ones_tensor: \n",
            " tensor([[[1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.]],\n",
            "\n",
            "        [[1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.]],\n",
            "\n",
            "        [[1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.]]]) \n",
            "\n",
            "zeros_tensor: \n",
            " tensor([[[0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.]],\n",
            "\n",
            "        [[0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.]],\n",
            "\n",
            "        [[0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.]]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 다음은 tensor의 속성(Attribute)을 표현하는 방법입니다.\n",
        "tensor = torch.rand(3,4)\n",
        "print(f\"Tensor shape: {tensor.shape}\")\n",
        "print(f\"Tensor datatype: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZdQmI_fJDO6",
        "outputId": "ed7a4367-3159-4b2c-c399-00b7c803efd5"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor shape: torch.Size([3, 4])\n",
            "Tensor datatype: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음은 Tensor의 연산(Operation)에 대해서 알아봅니다.\n",
        "\n",
        "일반적으로 GPU 환경에서 빠르게 실행됩니다."
      ],
      "metadata": {
        "id": "3hka6fDlJsAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# device 선택\n",
        "if torch.cuda.is_available():\n",
        "    tensor = tensor.to(\"cuda\")"
      ],
      "metadata": {
        "id": "24cYK7zgJ2z3"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(4,4)\n",
        "\n",
        "print(tensor)\n",
        "print(f\"first row: {tensor[0]}\")\n",
        "print(f\"first column: {tensor[:,0]}\")\n",
        "print(f\"last column: {tensor[:,-1]}\") #or tensor[..., -1]\n",
        "\n",
        "# column 값도 쉽게 바꿀 수 있습니다.\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS5zWmCmKBdZ",
        "outputId": "60186a64-6455-46b7-e3a9-f01e99c903ea"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7659, 0.9023, 0.7363, 0.9933],\n",
            "        [0.4812, 0.6392, 0.0427, 0.5420],\n",
            "        [0.5645, 0.3949, 0.2102, 0.5941],\n",
            "        [0.0621, 0.8549, 0.4632, 0.2220]])\n",
            "first row: tensor([0.7659, 0.9023, 0.7363, 0.9933])\n",
            "first column: tensor([0.7659, 0.4812, 0.5645, 0.0621])\n",
            "last column: tensor([0.9933, 0.5420, 0.5941, 0.2220])\n",
            "tensor([[0.7659, 0.0000, 0.7363, 0.9933],\n",
            "        [0.4812, 0.0000, 0.0427, 0.5420],\n",
            "        [0.5645, 0.0000, 0.2102, 0.5941],\n",
            "        [0.0621, 0.0000, 0.4632, 0.2220]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor 합치기(pandas의 concat과 같음. 행(or 열) 이어붙이기)\n",
        "t1 = torch.cat([tensor,tensor,tensor],dim = 1)\n",
        "print(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EJpLiYkKwel",
        "outputId": "4b20dff5-7284-490b-e791-f5cb209d6603"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7659, 0.0000, 0.7363, 0.9933, 0.7659, 0.0000, 0.7363, 0.9933, 0.7659,\n",
            "         0.0000, 0.7363, 0.9933],\n",
            "        [0.4812, 0.0000, 0.0427, 0.5420, 0.4812, 0.0000, 0.0427, 0.5420, 0.4812,\n",
            "         0.0000, 0.0427, 0.5420],\n",
            "        [0.5645, 0.0000, 0.2102, 0.5941, 0.5645, 0.0000, 0.2102, 0.5941, 0.5645,\n",
            "         0.0000, 0.2102, 0.5941],\n",
            "        [0.0621, 0.0000, 0.4632, 0.2220, 0.0621, 0.0000, 0.4632, 0.2220, 0.0621,\n",
            "         0.0000, 0.4632, 0.2220]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor 합치기(stack 사용, Tensor에 Tensor를 원소로 붙임)\n",
        "t2 = torch.stack([tensor,tensor,tensor],dim = 0)\n",
        "print(t2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTW_8Fi2LLaD",
        "outputId": "8bb6c27b-5782-4ddb-f0c0-07a62bf58fa7"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.7659, 0.0000, 0.7363, 0.9933],\n",
            "         [0.4812, 0.0000, 0.0427, 0.5420],\n",
            "         [0.5645, 0.0000, 0.2102, 0.5941],\n",
            "         [0.0621, 0.0000, 0.4632, 0.2220]],\n",
            "\n",
            "        [[0.7659, 0.0000, 0.7363, 0.9933],\n",
            "         [0.4812, 0.0000, 0.0427, 0.5420],\n",
            "         [0.5645, 0.0000, 0.2102, 0.5941],\n",
            "         [0.0621, 0.0000, 0.4632, 0.2220]],\n",
            "\n",
            "        [[0.7659, 0.0000, 0.7363, 0.9933],\n",
            "         [0.4812, 0.0000, 0.0427, 0.5420],\n",
            "         [0.5645, 0.0000, 0.2102, 0.5941],\n",
            "         [0.0621, 0.0000, 0.4632, 0.2220]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서는 일반적으로 matrix를 띄우기 때문에 행렬 곱을 정의할 수 있음.\n",
        "y1 = tensor@tensor.T\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "# y1과 같은 구조를 가진 Tensor를 만들고\n",
        "y3 = torch.rand_like(y1)\n",
        "# out를 y3로 지정하여 값만 바꿔넣는다.\n",
        "torch.matmul(tensor, tensor.T, out = y3)\n",
        "\n",
        "# 표현 형태만 다를 뿐 같은 행렬 곱연산이다.\n",
        "print(y1)\n",
        "print(y2)\n",
        "print(y3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkJcZhRuLwly",
        "outputId": "bd9199b2-5278-421c-b9b0-2d31a757e314"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.1154, 0.9383, 1.1772, 0.6092],\n",
            "        [0.9383, 0.5271, 0.6026, 0.1700],\n",
            "        [1.1772, 0.6026, 0.7158, 0.2643],\n",
            "        [0.6092, 0.1700, 0.2643, 0.2677]])\n",
            "tensor([[2.1154, 0.9383, 1.1772, 0.6092],\n",
            "        [0.9383, 0.5271, 0.6026, 0.1700],\n",
            "        [1.1772, 0.6026, 0.7158, 0.2643],\n",
            "        [0.6092, 0.1700, 0.2643, 0.2677]])\n",
            "tensor([[2.1154, 0.9383, 1.1772, 0.6092],\n",
            "        [0.9383, 0.5271, 0.6026, 0.1700],\n",
            "        [1.1772, 0.6026, 0.7158, 0.2643],\n",
            "        [0.6092, 0.1700, 0.2643, 0.2677]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# element 끼리의 곱도 정의할 수 있다 (inner_product over N-Real or N-complex)\n",
        "z1 = tensor*tensor\n",
        "z2 = tensor.mul(tensor)\n",
        "z3 = torch.rand_like(tensor)\n",
        "torch.mul(tensor, tensor, out = z3)\n",
        "\n",
        "print(z1)\n",
        "print(z2)\n",
        "print(z3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV-6Bn_cMy6u",
        "outputId": "48571d1e-e3db-433a-cfc2-64e60931b846"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5866, 0.0000, 0.5421, 0.9867],\n",
            "        [0.2315, 0.0000, 0.0018, 0.2937],\n",
            "        [0.3186, 0.0000, 0.0442, 0.3529],\n",
            "        [0.0039, 0.0000, 0.2146, 0.0493]])\n",
            "tensor([[0.5866, 0.0000, 0.5421, 0.9867],\n",
            "        [0.2315, 0.0000, 0.0018, 0.2937],\n",
            "        [0.3186, 0.0000, 0.0442, 0.3529],\n",
            "        [0.0039, 0.0000, 0.2146, 0.0493]])\n",
            "tensor([[0.5866, 0.0000, 0.5421, 0.9867],\n",
            "        [0.2315, 0.0000, 0.0018, 0.2937],\n",
            "        [0.3186, 0.0000, 0.0442, 0.3529],\n",
            "        [0.0039, 0.0000, 0.2146, 0.0493]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# single element tensor인 경우, item()을 이용하여 value를 추출할 수 있다.\n",
        "agg = tensor.sum()\n",
        "print(agg)\n",
        "agg_value = agg.item()\n",
        "print(agg_value, type(agg_value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0VZh4gXNWxm",
        "outputId": "a4a743eb-7ae9-43bb-e1f6-6fb35ad79ce9"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5.6774)\n",
            "5.6774420738220215 <class 'float'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor에 add연산을하면 바꿔치기 연산(in-place)이 가능함.\n",
        "\n",
        "ts = torch.ones(3,3)\n",
        "print(f\"original tensor: \\n{ts} \\n\")\n",
        "ts.add_(4)\n",
        "print(f\"inplace tensor: \\n{ts} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ev9Xw8pBN3Lb",
        "outputId": "958e3afe-a2e1-48ce-9b8e-2d54b167d521"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original tensor: \n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "inplace tensor: \n",
            "tensor([[5., 5., 5.],\n",
            "        [5., 5., 5.],\n",
            "        [5., 5., 5.]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. DATASET과 DATALOADER"
      ],
      "metadata": {
        "id": "gfRRog6BOWiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST 데이터 내려받기\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNta7G9s8twl",
        "outputId": "adf9b71f-ac88-42fd-b9ff-48ea8d49127a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 11884163.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 199875.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3747021.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 16647861.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch size: 데이터로더 객체의 각 요소는 64개의 feature와 label을 가진 묶음으로 반환 즉 (64 x feature su) matrix와 (64x1) label matrix 반환\n",
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size = batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size = batch_size)\n",
        "\n",
        "for x, y in test_dataloader:\n",
        "    print(f\"Shape of X[N, C, H, W]: {x.shape}\")\n",
        "    print(f\"Shape of y: {y.shape}, {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIiKRIyk81uT",
        "outputId": "8f6d4d02-8315-46dc-8ddf-c9c750774fb2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X[N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]), torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "직관적으로 N, C, H, W가 어떤 값인지 정확하게 알 수 없습니다. 따라서 간단한 예시를 통해 이해해봅니다."
      ],
      "metadata": {
        "id": "Y0wj7LXG_mr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in list(test_dataloader)[:1]:\n",
        "    print(x, y)\n",
        "    print(x[0])\n",
        "    print(x.size(), y.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jouXQayN-bDh",
        "outputId": "ba915bf8-4d01-46ce-b7b8-5bf70e0565db"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 4, 8, 0, 2, 5, 7, 9,\n",
            "        1, 4, 6, 0, 9, 3, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 6, 1, 3, 7, 6, 7, 2, 1,\n",
            "        2, 2, 4, 4, 5, 8, 2, 2, 8, 4, 8, 0, 7, 7, 8, 5])\n",
            "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0118, 0.0039, 0.0000, 0.0000, 0.0275,\n",
            "          0.0000, 0.1451, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0078, 0.0000,\n",
            "          0.1059, 0.3294, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.4667, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
            "          0.3451, 0.5608, 0.4314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0863,\n",
            "          0.3647, 0.4157, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.0000, 0.2078,\n",
            "          0.5059, 0.4706, 0.5765, 0.6863, 0.6157, 0.6510, 0.5294, 0.6039,\n",
            "          0.6588, 0.5490, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0431, 0.5373,\n",
            "          0.5098, 0.5020, 0.6275, 0.6902, 0.6235, 0.6549, 0.6980, 0.5843,\n",
            "          0.5922, 0.5647, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000,\n",
            "          0.0078, 0.0039, 0.0000, 0.0118, 0.0000, 0.0000, 0.4510, 0.4471,\n",
            "          0.4157, 0.5373, 0.6588, 0.6000, 0.6118, 0.6471, 0.6549, 0.5608,\n",
            "          0.6157, 0.6196, 0.0431, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0118, 0.0000, 0.0000, 0.3490, 0.5451, 0.3529,\n",
            "          0.3686, 0.6000, 0.5843, 0.5137, 0.5922, 0.6627, 0.6745, 0.5608,\n",
            "          0.6235, 0.6627, 0.1882, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0157,\n",
            "          0.0039, 0.0000, 0.0000, 0.0000, 0.3843, 0.5333, 0.4314, 0.4275,\n",
            "          0.4314, 0.6353, 0.5294, 0.5647, 0.5843, 0.6235, 0.6549, 0.5647,\n",
            "          0.6196, 0.6627, 0.4667, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0078, 0.0078, 0.0039, 0.0078, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.1020, 0.4235, 0.4588, 0.3882, 0.4353, 0.4588,\n",
            "          0.5333, 0.6118, 0.5255, 0.6039, 0.6039, 0.6118, 0.6275, 0.5529,\n",
            "          0.5765, 0.6118, 0.6980, 0.0000],\n",
            "         [0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0824,\n",
            "          0.2078, 0.3608, 0.4588, 0.4353, 0.4039, 0.4510, 0.5059, 0.5255,\n",
            "          0.5608, 0.6039, 0.6471, 0.6667, 0.6039, 0.5922, 0.6039, 0.5608,\n",
            "          0.5412, 0.5882, 0.6471, 0.1686],\n",
            "         [0.0000, 0.0000, 0.0902, 0.2118, 0.2549, 0.2980, 0.3333, 0.4627,\n",
            "          0.5020, 0.4824, 0.4353, 0.4431, 0.4627, 0.4980, 0.4902, 0.5451,\n",
            "          0.5216, 0.5333, 0.6275, 0.5490, 0.6078, 0.6314, 0.5647, 0.6078,\n",
            "          0.6745, 0.6314, 0.7412, 0.2431],\n",
            "         [0.0000, 0.2667, 0.3686, 0.3529, 0.4353, 0.4471, 0.4353, 0.4471,\n",
            "          0.4510, 0.4980, 0.5294, 0.5333, 0.5608, 0.4941, 0.4980, 0.5922,\n",
            "          0.6039, 0.5608, 0.5804, 0.4902, 0.6353, 0.6353, 0.5647, 0.5412,\n",
            "          0.6000, 0.6353, 0.7686, 0.2275],\n",
            "         [0.2745, 0.6627, 0.5059, 0.4078, 0.3843, 0.3922, 0.3686, 0.3804,\n",
            "          0.3843, 0.4000, 0.4235, 0.4157, 0.4667, 0.4706, 0.5059, 0.5843,\n",
            "          0.6118, 0.6549, 0.7451, 0.7451, 0.7686, 0.7765, 0.7765, 0.7333,\n",
            "          0.7725, 0.7412, 0.7216, 0.1412],\n",
            "         [0.0627, 0.4941, 0.6706, 0.7373, 0.7373, 0.7216, 0.6706, 0.6000,\n",
            "          0.5294, 0.4706, 0.4941, 0.4980, 0.5725, 0.7255, 0.7647, 0.8196,\n",
            "          0.8157, 1.0000, 0.8196, 0.6941, 0.9608, 0.9882, 0.9843, 0.9843,\n",
            "          0.9686, 0.8627, 0.8078, 0.1922],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0471, 0.2627, 0.4157, 0.6431, 0.7255,\n",
            "          0.7804, 0.8235, 0.8275, 0.8235, 0.8157, 0.7451, 0.5882, 0.3216,\n",
            "          0.0314, 0.0000, 0.0000, 0.0000, 0.6980, 0.8157, 0.7373, 0.6863,\n",
            "          0.6353, 0.6196, 0.5922, 0.0431],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이미지 데이터의 구조는 $28*28$의 tensor로 구성되어 있고, 그 tensor가 fashionMNIST의 원소가 됩니다. 즉, 하나의 이미지를 $28*28$ tensor로 표현한다는 의미입니다. \n",
        "\n",
        "batch_size를 64로 두었으니, 해당 데이터는 64개의 tensor와 그 tensor의 label 데이터를 불러옵니다. 예시로 해당 이미지를 visualized 해봅니다."
      ],
      "metadata": {
        "id": "atncZTquATrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 1, 1\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = 0\n",
        "    img, label = list(test_dataloader)[sample_idx]\n",
        "    img = img[0]\n",
        "    label = label[0].item()\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "nrerIUzUBLJH",
        "outputId": "e5c804b4-bccb-4249-a098-b828a1b6090c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test_dataloader에서 첫번째 batch에 첫 원소(tensor)를 시각화하였습니다. Domain의 정보를 이용하여 Labeling을 해주고, plt의 imshow를 이용하여 tensor를 시각화합니다."
      ],
      "metadata": {
        "id": "Ocgt1QaJDYUD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음은 custom DataSet을 만드는 방법입니다. Dataset 클래스를 만들 때 반드시 3개의 함수를 구현해야합니다:\n",
        "* \\_\\_init\\_\\_\n",
        "* \\_\\_len\\_\\_\n",
        "* \\_\\_getitem\\_\\_"
      ],
      "metadata": {
        "id": "MLvuDu_qxaCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    # __init__ 함수는 Dataset 객체가 생성될 때 한 번만 실행됨. 여기서 이미지와 label이 포함된 디텍토리와 transform을 초기화 함.\n",
        "    def __init__(self, annotations_file, img_dir, transform = None, target_transform = None):\n",
        "        self.img_labels = pd.read_csv(annotations_file, names = ['file_name', 'label'])\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "    # __len__ 함수는 데이터셋의 샘플 개수를 반환\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "    # __getitem__ 함수는 주어진 idx로 샘플을 데이터셋에서 불러오고 반환한 후, 해당 label과 transform을 진행함.\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx,1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label) \n",
        "        # sample = {\"image\": image, \"label\": label} < 해당작업을 하면 dict형태로 반환 가능\n",
        "        return image, label #  sample"
      ],
      "metadata": {
        "id": "4lzF5maUyOqo"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset은 Feature와 label을 지정하는 일을 한 번에 한다. \n",
        "\n",
        "DataLoader는 모델을 훈련할 때, 샘플들을 minibatch로 전달하고, epoch마다 데이터를 섞어서 과적합(overfit)을 막고, multiprocessing을 사용하여 검색 속도를 높이는 작업을 추상화한 순회 가능한 객체(iterable)이다."
      ],
      "metadata": {
        "id": "Yn1DQNBO16Qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size= 64, shuffle = True)\n",
        "test_dataloader = DataLoader(test_data, batch_size= 64, shuffle = True)"
      ],
      "metadata": {
        "id": "_PndryHfygdD"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# iter로 반복가능한 객체에서 iterater를 반환하고 next를 통해 값을 차례대로 꺼낸다.\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap = 'gray')\n",
        "plt.title(labels_map[label.item()])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "8ZuTTsf627mn",
        "outputId": "161679c1-db15-4033-f0a4-b25e3f170752"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. TRANSFORM\n",
        "학습에 필요한 데이터를 조작하여 학습에 적합하게 만드는 작업을 transform이라 한다.\n",
        "\n",
        "학습을 하려면 정규화(normalize)된 tensor형태의 feature와 one-hat으로 encoding된 label이 필요하다. 이러한 transform을 위해 ToTensor와 Lambda를 이용한다."
      ],
      "metadata": {
        "id": "GlCLh-sH4001"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import ToTensor, Lambda\n",
        "\n",
        "ds = datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    train = True,\n",
        "    download = True,\n",
        "    # ToTensor은 ndarray를 FloatTensor로 변환하고, 픽셀의 크기를 [0,1] 범위로 비례 조정(scale)\n",
        "    transform = ToTensor(),\n",
        "    # torch.zeros(10)으로 한 이유는 label target이 0 ~ 9이므로 타겟의 갯수를 의미한다. \n",
        "    # value 1은 해당 one-hat encode된 tensor에 정답에 해당하는 위치에 value 1을 할당함. \n",
        "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
        "    )   "
      ],
      "metadata": {
        "id": "2Xx6qbA29TUZ"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhPg2NAz957k",
        "outputId": "b2055200-553e-408c-f212-59c1fb76947e"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()\n",
              "Target transform: Lambda()"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 신경망 모델 구성\n"
      ],
      "metadata": {
        "id": "y5y2HYoRJtYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 신경망을 구성하는데 필요한 모든 구성요소를 제공하는  API\n",
        "from torch import nn\n",
        "\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF43UA-nbaGB",
        "outputId": "2e7534a9-ba3b-450c-d9b4-ec19ab63da1c"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ts = torch.rand(4,1,5,5) \n",
        "flatten = nn.Flatten()\n",
        "\n",
        "print(ts.shape)\n",
        "f_ts = flatten(ts)\n",
        "print(f_ts.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6cZpGgQfixA",
        "outputId": "8b3e8b29-fa2c-47c3-b547-862f991c55bb"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 1, 5, 5])\n",
            "torch.Size([4, 25])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Flatten은 tensor 내 matrix의 size를 1차원으로 바꿔준다.\n",
        "        # ex) tensor in (4,1,5,5) > Flatten(tensor) in (4,25)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            # Linear 함수는 in_feature의 size를 out_feature의 size로 전환한다.\n",
        "            nn.Linear(28*28, 512),\n",
        "            # ReLU함수는 max(0,x)를 반환하는 활성화 함수이다.\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512,10),\n",
        "        )\n",
        "    # nn.Module을 상속받은 모든 클래스는 foward 메소드에 입력 데이터에 대한 연산을 구현\n",
        "    def forward(self, x):\n",
        "        x= self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "faCgQsmFb8zz"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GBBnGxMgUG5",
        "outputId": "567c39e4-aba1-4465-ffc0-e204925d3597"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(1,28,28, device = device)\n",
        "logits = model(X)\n",
        "pred_prob = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_prob.argmax(1)\n",
        "\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpUcHX1OgYB9",
        "outputId": "241e5d5d-e5cb-4fb7-ae46-52ef07514faf"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_image = torch.rand(3,28,28)\n",
        "print(input_image.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKK60oipjBkU",
        "outputId": "d9465594-515e-42eb-f8d2-cd150a786334"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn.Flatten은 계층을 초기화하여 $28*28$의 2D이미지를 784픽셀을 갖는 연속된 배열로 변환함."
      ],
      "metadata": {
        "id": "B1TEIysjjsHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flatten = nn.Flatten()\n",
        "flat_image = flatten(input_image)\n",
        "print(flat_image.size()) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unPP608djTPY",
        "outputId": "05860c9b-8684-4ab8-8be4-0df3e31009ea"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn.Linear은 저장된 가중치(weight)와 편향(bias)를 사용하여 선형 변환(linear transformation)을 적용하는 모듈."
      ],
      "metadata": {
        "id": "KmIWEmNdlNJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer1 = nn.Linear(in_features = 28*28, out_features=20)\n",
        "hidden1 = layer1(flat_image)\n",
        "print(hidden1.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ-8Iz5dmuGj",
        "outputId": "f9083cd6-15a8-4bdc-92ac-621459e9f009"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn.ReLU는 모델의 입력과 출력 사이에 복잡한 관계(mapping)을 만들어 줍니다. 비선형 활성화(activation)는 선형 변환 후 적용되어 비선형성(nonlinearlity)을 도입하고, 신경망이 다양한 현상을 학습할 수 있도록 돕습니다.\n",
        "\n",
        "$$ReLU(x) = max(x,0)$$"
      ],
      "metadata": {
        "id": "peQAbxUrpoBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
        "hidden1 = nn.ReLU()(hidden1)\n",
        "print(f\"After ReLU: {hidden1}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC0hX5cWqG1N",
        "outputId": "94edd32d-45db-40f0-c922-2ac654fc31de"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before ReLU: tensor([[ 0.1219,  0.2506,  0.0504, -0.1790, -0.1340, -0.2326, -0.2579,  0.3790,\n",
            "          0.4477, -0.6001,  0.4369, -0.2226, -0.3978, -0.4360, -0.3871, -0.1809,\n",
            "          0.0406,  0.0929, -0.1111, -0.5587],\n",
            "        [ 0.2842, -0.0202, -0.2119, -0.0496, -0.2711, -0.3019, -0.3268,  0.1807,\n",
            "          0.3132, -0.2900,  0.2277, -0.5709, -0.3752,  0.0013, -0.4196,  0.0128,\n",
            "          0.1511,  0.3781, -0.0662, -0.1961],\n",
            "        [ 0.0867,  0.0422, -0.0814, -0.2201, -0.1080,  0.0378, -0.2991,  0.0116,\n",
            "          0.3939,  0.0376,  0.3201, -0.1414, -0.0162, -0.4763, -0.5261,  0.0272,\n",
            "         -0.0800,  0.3478, -0.0025, -0.5243]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "\n",
            "After ReLU: tensor([[0.1219, 0.2506, 0.0504, 0.0000, 0.0000, 0.0000, 0.0000, 0.3790, 0.4477,\n",
            "         0.0000, 0.4369, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0406, 0.0929,\n",
            "         0.0000, 0.0000],\n",
            "        [0.2842, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1807, 0.3132,\n",
            "         0.0000, 0.2277, 0.0000, 0.0000, 0.0013, 0.0000, 0.0128, 0.1511, 0.3781,\n",
            "         0.0000, 0.0000],\n",
            "        [0.0867, 0.0422, 0.0000, 0.0000, 0.0000, 0.0378, 0.0000, 0.0116, 0.3939,\n",
            "         0.0376, 0.3201, 0.0000, 0.0000, 0.0000, 0.0000, 0.0272, 0.0000, 0.3478,\n",
            "         0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn.Sequential은 순서를 갖는 모듈의 컨테이너입니다. 즉, 데이터는 정의된 순서대로 모든 모듈들을 통해 전달됩니다. sequential container를 이용하여 신경망을 빠르게 만들 수 있습니다."
      ],
      "metadata": {
        "id": "gcz5Sn7nqnxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_modules = nn.Sequential(\n",
        "    flatten,\n",
        "    layer1,\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20,10)\n",
        ")\n",
        "input_image = torch.rand(3,28,28)\n",
        "logits = seq_modules(input_image)\n",
        "print(f\"After Seq_modules size: {logits.size()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpOgCZEkq9oU",
        "outputId": "da92548a-11db-44c4-c225-63cc1871f9df"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Seq_modules size: torch.Size([3, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn.Softmax 신경망의 마지막 선형 계층은 모듈에 전달될 logits를 반환합니다. logits는 모델의 분류(class)에 대한 예측 확률을 $[0,1]$ 범위로 비례하여 조정(scale)된다. dim 매개변수는 값의 합이 1이 되는 차원을 나타낸다\n",
        "\n",
        "$$ Softmax(x_{i}) = \\frac{exp(x_{i})}{\\sum_{j} exp(x_j)} $$"
      ],
      "metadata": {
        "id": "S3l_poHFrcNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "softmax = nn.Softmax(dim = 1)\n",
        "pred_prob = softmax(logits)\n",
        "\n",
        "# 3 - minibatch의 결과 값\n",
        "print(pred_prob.argmax(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZsMVPrSsF2W",
        "outputId": "81f46aaf-da61-4362-b6af-dea1c14065ea"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "신경망 내부의 많은 계층들은 매개변수화(parameterize)된다. 즉, 학습 중에 최적화되는 가중치(weight)와 편향(bias)과 연관되어 진다."
      ],
      "metadata": {
        "id": "yX60E-5Us_MZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model structure: {model}\\n\\n\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeKeLrlzs0jt",
        "outputId": "201b5ce0-cd56-4840-deaa-24f674c0a36f"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure: NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "\n",
            "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-2.9564e-02, -1.2294e-02,  2.2396e-02,  ..., -1.3959e-02,\n",
            "         -1.5758e-02,  3.8164e-03],\n",
            "        [-8.1995e-03, -3.2477e-02,  6.3151e-04,  ...,  2.7809e-02,\n",
            "         -9.3264e-05,  2.9120e-02]], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([ 0.0273, -0.0333], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0263, -0.0072, -0.0183,  ...,  0.0330,  0.0058,  0.0014],\n",
            "        [ 0.0056,  0.0333,  0.0339,  ...,  0.0403,  0.0139,  0.0267]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0408,  0.0240], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0052, -0.0188, -0.0132,  ...,  0.0441,  0.0047, -0.0436],\n",
            "        [ 0.0226,  0.0340,  0.0232,  ..., -0.0433, -0.0181,  0.0403]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-9.6738e-05,  1.5843e-02], grad_fn=<SliceBackward0>) \n",
            "\n"
          ]
        }
      ]
    }
  ]
}