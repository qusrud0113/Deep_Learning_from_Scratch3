{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOd+Dqm0qn98AJKVwhvz4xP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qusrud0113/PyTorch-tutorial/blob/main/2023_05_Pytorch_tutorial_(4).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.4.2 nn.Module로 구현하는 로지스틱 회귀"
      ],
      "metadata": {
        "id": "rgai5SlzKKa-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oE97xClWKHmJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as  optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwS4pPiiKXzK",
        "outputId": "f5f05706-40b8-43ad-ffe0-c97674fddbdf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f51dcb99290>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "X_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)"
      ],
      "metadata": {
        "id": "DKHGi1CrKaV2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn.Sequential은 nn.Module층을 쌓을 수 있도록 함. 즉 nn.Sequential은 최적화 함수와 시그모이드 함수 등을 연결시켜주는 역할"
      ],
      "metadata": {
        "id": "HxHORt_gKrt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(2,1), #input_dim = 2, output_dim = 1\n",
        "    nn.Sigmoid() # 출력은 Sigmoid함수 사용\n",
        ")"
      ],
      "metadata": {
        "id": "NuoJiiR5KcPA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(X_train) #현재는 W와 b가 랜덤하게 배정된 상태라 의미 X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oRn2IrJK6ti",
        "outputId": "6c8be84d-4a99-4496-9d52-a1a3a3b6e32e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4020],\n",
              "        [0.4147],\n",
              "        [0.6556],\n",
              "        [0.5948],\n",
              "        [0.6788],\n",
              "        [0.8061]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " optimizer = optim.SGD(model.parameters(), lr = 1)\n",
        " epochs = 1000\n",
        " for epoch in range(epochs+1):\n",
        "    hx = model(X_train)\n",
        "    cost = F.binary_cross_entropy(hx, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        pred = hx >= torch.FloatTensor([0.5])\n",
        "        crr_pred = pred.float() == y_train\n",
        "        acc = crr_pred.sum().item()/len(crr_pred)\n",
        "\n",
        "        print(f'Epoch: {epoch}, cost: {round(cost.item(), 6)}, Accuracy: {round(acc*100,2)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9h58TXhLI68",
        "outputId": "1c3a1062-e159-4de5-8fc5-23324ee50bcb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, cost: 0.539713, Accuracy: 83.33\n",
            "Epoch: 100, cost: 0.134272, Accuracy: 100.0\n",
            "Epoch: 200, cost: 0.080486, Accuracy: 100.0\n",
            "Epoch: 300, cost: 0.05782, Accuracy: 100.0\n",
            "Epoch: 400, cost: 0.045251, Accuracy: 100.0\n",
            "Epoch: 500, cost: 0.037228, Accuracy: 100.0\n",
            "Epoch: 600, cost: 0.031649, Accuracy: 100.0\n",
            "Epoch: 700, cost: 0.027538, Accuracy: 100.0\n",
            "Epoch: 800, cost: 0.024381, Accuracy: 100.0\n",
            "Epoch: 900, cost: 0.021877, Accuracy: 100.0\n",
            "Epoch: 1000, cost: 0.019843, Accuracy: 100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(X_train) >= torch.FloatTensor([0.5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xb4hhYYQMcO-",
        "outputId": "282126d8-0d4a-4f50-dc8e-fbeb63c4894e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# after training weight and bias\n",
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDnKDUtcMmZR",
        "outputId": "d2255bb4-912d-4b11-d090-9a3f400ebe50"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[3.2534, 1.5181]], requires_grad=True), Parameter containing:\n",
            "tensor([-14.4839], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.4.3 클래스로 파이토치 모델 구현"
      ],
      "metadata": {
        "id": "Fq8nX4W7OAZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class binaryclassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(2,1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.linear(x))"
      ],
      "metadata": {
        "id": "55TvWNVkOEMS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Qnwh0yZ2m7l",
        "outputId": "eed3ca1f-7305-471a-dfc9-513b348ccb0f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f51dcb99290>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = binaryclassifier()"
      ],
      "metadata": {
        "id": "h28A95tu2ppd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr = 1)\n",
        "epochs = 1000\n",
        "for epoch in range(epochs +1):\n",
        "    hx = model(X_train)\n",
        "    cost = F.binary_cross_entropy(hx, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch %100 == 0:\n",
        "        pred = hx >= torch.FloatTensor([0.5])\n",
        "        crr_pred = pred.float() == y_train\n",
        "        acc = crr_pred.sum().item()/len(crr_pred)\n",
        "\n",
        "        print(f'Epoch: {epoch}, cost: {round(cost.item(), 6)}, Accuracy: {round(acc*100,2)}')        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdfXcHBU2u9d",
        "outputId": "7e68a4e7-38ea-4744-ac5f-71e0821a1454"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, cost: 0.539713, Accuracy: 83.33\n",
            "Epoch: 100, cost: 0.134272, Accuracy: 100.0\n",
            "Epoch: 200, cost: 0.080486, Accuracy: 100.0\n",
            "Epoch: 300, cost: 0.05782, Accuracy: 100.0\n",
            "Epoch: 400, cost: 0.045251, Accuracy: 100.0\n",
            "Epoch: 500, cost: 0.037228, Accuracy: 100.0\n",
            "Epoch: 600, cost: 0.031649, Accuracy: 100.0\n",
            "Epoch: 700, cost: 0.027538, Accuracy: 100.0\n",
            "Epoch: 800, cost: 0.024381, Accuracy: 100.0\n",
            "Epoch: 900, cost: 0.021877, Accuracy: 100.0\n",
            "Epoch: 1000, cost: 0.019843, Accuracy: 100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0.5 소프트맥스 회귀(Softmax Regression)\n",
        "## 0.5.1 원-핫 인코딩(One-Hot Encoding)\n",
        "> 원 - 핫 인코딩\n",
        "\n",
        "선택해야하는 선택지의 개수만큼의 차원을 가지면서, 각 선택지에 해당하는 인덱스의 원소에는 1, 나머지엔 0을 갖도록하는 표현 방법.\n",
        "\n",
        "    예시)\n",
        "    강아지 = [1, 0, 0]\n",
        "    고양이 = [0, 1, 0]\n",
        "    냉장고 = [0, 0, 1] \n",
        "\n",
        "> 원 - 핫 벡터의 무작위성\n",
        "\n",
        "각 클래스 간의 관계가 균등하다는 이점이 존재함. 바나나, 토마토, 사과를 분류하는 문제가 있다고 생각하자. 라벨인코딩을 이용하면 각 클래스가 정수로 넘버링 된다.\n",
        "\n",
        "    바나나 = 1\n",
        "    토마토 = 2\n",
        "    사과 = 3\n",
        "\n",
        " 예를 들어 평가 방법이 MSE(Mean Squre Error)일 때 \n",
        " $$ \\text{Loss function} = \\frac{1}{n} \\sum_{i=1}^{n}(y_{i} - \\hat{y}_{i})\n",
        " ^{2}, $$ 실제값이 토마토일 때, 예측값이 바나나라면 제곱 오차는 $$(2-1)^2 = 1$$이 되고, 실제값이 사과일 때, 예측값이 바나나라면 제곱 오차는 $$(3-1)^2 = 4$$가 된다. 즉, 예측값이 바나나일때, 실제값이 토마토일때의 오차보다 사과일때의 오차가 크므로, 바나나가 토마토에 가깝다는 정보를 얻는 것과 같다. \n",
        "\\\n",
        "\\\n",
        " 이러한 인코딩 방식은 순서 정보가 도움이 되는 분류문제를 풀거나 회귀를 통한 분류문제를 풀 때 이점이 있다. 하지만 대부분의 다중 클래스 분류문제는 각 클래스간의 순서의 의미가 없기 때문에 라벨인코딩 보단 원-핫 인코딩을 통해 클래스간의 관계를 균등하게 두는 것이 좋다.\n",
        "\n",
        "    바나나 = [1, 0, 0]\n",
        "    토마토 = [0, 1, 0]\n",
        "    사과 = [0, 0, 1] \n",
        "이렇게 균등 오차를 계산하게 되면\n",
        "$$ ((0,1,0) - (1,0,0))^2 = (0-1)^2 + (0-1)^2 + (0-0)^2 = 2 $$\n",
        "$$ ((0,1,0) - (0,0,1))^2 = (0-0)^2 + (1-0)^2 + (0-1)^2 = 2 $$\n",
        "가 되어 모든 클래스간의 오차가 균등함을 보여준다.\n",
        " "
      ],
      "metadata": {
        "id": "Q-P-Z2_u31cL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.5.2 소프트맥스 회귀 이해하기\n",
        "소프트맥스 회귀를 통하여 다중 클래스 분류(Multi-Class Classification) 문제를 해결해보자.\n",
        "\n",
        "\n",
        ">소프트맥스 함수\n",
        "\n",
        "분류해야하는 클래스가 k개 일때, k차원의 벡터를 입력 받아 각 클래스에 대한 확률을 추정한다. k차원의 벡터에서 i번째 원소를 $z_{i}$, i번째 클래스가 정답일 확률을 $p_{i}$로 정의할 때, 소프트맥스 함수는 $p_{i}$를 다음과 같이 정의한다: $$p_{i} = \\frac{e^{z_{i}}}{\\sum_{j=1}^{k} e^{z_{j}}} \\quad for \\quad i=1,2,\\dots, k$$\n",
        "\n",
        "따라서 $z = (z_{1},\\dots, z_{k})$일때, softmax function은 $$softmax(z) = \\bigg(\\frac{e^{z_{1}}}{\\sum_{j=1}^{k} e^{z_{j}}},\\dots, \\frac{e^{z_{k}}}{\\sum_{j=1}^{k} e^{z_{j}}}\\bigg) = (p_{1},\\dots,p_{k}), \\quad where \\quad \\sum_{i=1}^{k}p_{i} = 1$$\n",
        "이다.\n",
        "\n",
        "\n",
        "> 크로스 엔트로피 함수\n",
        "\n",
        "소프트맥스 회귀에서는 cost function을 크로스 엔트로피 함수를 사용한다:\n",
        "    \n",
        "    Define\n",
        "    y : 실제값\n",
        "    k : class 수\n",
        "    p_j : j번째 클래스일 확률\n",
        "\n",
        "$$ cost(W) = -\\sum_{j=1}^{j} y_{j}ln(p_{j}) = -ln(p_{c}) \\quad \\text{if c-th index is solution}$$\n",
        "이를 $n$개의 전체 데이터에 대한 평균으로 구한다면, 최종 비용 함수는 다음과 같다:\n",
        "$$ cost(W) = -\\frac{1}{n}\\sum_{i=1}^{n}\\sum_{j=1}^{k} y_{j}^{(i)}ln(p_{j}^{(i)}) $$\n",
        "\n",
        "\n",
        "\n",
        "## 0.5.3 소프트맥스 회귀의 비용 함수 구현\n"
      ],
      "metadata": {
        "id": "CfQV63ri-wd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "Neqof81j-8gk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xQksWTtLBSP",
        "outputId": "bd233d0c-96bc-4b47-8b42-530f1946e61f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f51dcb99290>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.FloatTensor([1,2,3])"
      ],
      "metadata": {
        "id": "oTJP6GEWLDn4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hx = F.softmax(z, dim = 0)\n",
        "print(hx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INW_z7dELMpE",
        "outputId": "9b1e906d-e253-4390-cac5-38d47f31b554"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0900, 0.2447, 0.6652])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(hx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goJ1FWSALRLI",
        "outputId": "ccbdf038-f6f5-4d7b-c524-96be79036739"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.rand(3, 5 , requires_grad =True)"
      ],
      "metadata": {
        "id": "WXM3CjWfLb2P"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dim 0,1은 softmax를 적용할 dim 위치임. 만약 dim이 1이면 열의 합이 1이 되게하는 softmax함수임\n",
        "hx2 = F.softmax(z, dim = 1)\n",
        "print(hx2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C1SlA4LLVL8",
        "outputId": "30c92233-0941-4535-d107-a6efe0ee0515"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2645, 0.1639, 0.1855, 0.2585, 0.1277],\n",
            "        [0.2430, 0.1624, 0.2322, 0.1930, 0.1694],\n",
            "        [0.2226, 0.1986, 0.2326, 0.1594, 0.1868]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.randint(low, high, size): low~high 사이에 정수를 뽑은 뒤 size 크기의 tensor 만들기\n",
        "y = torch.randint(5, (3,)).long()\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIZ3H1BLL7cL",
        "outputId": "d6de153c-2654-4fb2-d31a-9d31c0fc1e98"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 2, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot encoding\n",
        "# 3x5의 모든 원소가 0인 tensor 생성\n",
        "y_one_hot = torch.zeros_like(hx2) \n",
        "# y.unsqueeze(1)은 1x3인 tensor를 3x1 tensor로 전환\n",
        "# scatter(dim, value_index, apply_value)\n",
        "# scatter함수를 통해 dim = 1(열) 중, y의 값을 위치로 변환하여, apply_value = 1로 변환.\n",
        "# scatter 이후 '_'는 inplace operation임. \n",
        "y_one_hot.scatter_(1, y.unsqueeze(1), 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEKbrvjkNG3x",
        "outputId": "82d4697f-4b96-4a0f-899f-f6d5150a5124"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cost 함수 구현\n",
        "cost = (y_one_hot*-torch.log(hx2)).sum(dim = 1).mean()\n",
        "print(cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BexYPe2UPnp8",
        "outputId": "89c94528-557e-4b0f-d97b-a123c2eb539f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.4689, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "실제 계산식\n",
        "$$ cost(W) = -\\frac{1}{3}\\sum_{i=1}^{3}\\sum_{j=1}^{k} y_{j}^{(i)}ln(p_{j}^{(i)}) = \\frac{1}{3}(-1*ln(0.1855) - 1*ln(0.2322) - 1*ln(0.1986)) = 1.46884$$"
      ],
      "metadata": {
        "id": "MuyeJV-kUE8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# another method of cross_entropy\n",
        "# using F.log_softmax()\n",
        "(y_one_hot*-F.log_softmax(z, dim =1)).sum(dim=1).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JrglgiWa6ma",
        "outputId": "4ec5cf75-d55a-408c-e560-0be22b118978"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.4689, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# not using one-hot encoding\n",
        "F.nll_loss(F.log_softmax(z,dim = 1), y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AItkV95bRTM",
        "outputId": "3dc88c2e-77b9-4ac0-e273-44f63fd3b0fa"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.4689, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nll은 Negative Log Likelihood의 약자입니다."
      ],
      "metadata": {
        "id": "5lJtLdPzbcIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# final method\n",
        "F.cross_entropy(z, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD_NzIhPbjFD",
        "outputId": "34f0daf0-3814-4703-f59a-0083e12019dc"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.4689, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "F.cross_entropy는 cost함수와 softmax함수가 포함되어 있어 구현시 혼동이 가능할 수 있습니다."
      ],
      "metadata": {
        "id": "a1Rf_VrdbrKM"
      }
    }
  ]
}